[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is Project 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nJaqueline Vallejo Hinojosa\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nJaqueline Vallejo Hinojosa\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project4/hw2_questions.html",
    "href": "blog/project4/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd \n\nblueprinty = pd.read_csv('blueprinty.csv')\nblueprinty.head()\n\npatents_num = blueprinty.groupby('iscustomer')['patents'].mean()\npatents_num\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.histplot(data=blueprinty, x='patents', hue='iscustomer', multiple='stack', bins=20)\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.xlabel('Number of Patents')\nplt.ylabel('Count')\nplt.show()\n\n\n\n\n\n\n\n\n\nThe histogram shows that non-customers consistently outnumber customers across patent counts, with most entities, regardless of customer status, tend to hold 3–4 patents.\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nregion_counts = blueprinty.groupby(['iscustomer', 'region']).size().unstack()\n#print(region_counts)\n\nregion_counts.T.plot(kind='bar', stacked=True)\nplt.title('Customer Status by Region')\nplt.xlabel('Region')\nplt.ylabel('Count')\nplt.legend(title='Customer Status')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe chart shows that the Northeast has the highest overall customer count and a relatively balanced customer-to-non-customer ratio, while all other regions are dominated by non-customers.\n\n\nimport matplotlib.pyplot as plt\n\nblueprinty.boxplot(column='age', by='iscustomer')\nplt.title('Age Distribution by Customer Status')\nplt.suptitle('')\nplt.xlabel('Customer Status')\nplt.ylabel('Age')\nplt.show()\n\n\n\n\n\n\n\n\n\nThe age distribution for customers and non-customers is similar, with both groups centered around the mid-to-late 20s, though customers show slightly higher age variability and a marginally higher median\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nFor a random variable \\(Y \\sim \\text{Poisson}(\\lambda)\\), we consider the probability mass function (PMF):\n\\[\nf(Y \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^Y}{Y!}\n\\]\nIf we observe independent data points \\(Y_1, Y_2, \\dots, Y_n\\) from a Poisson distribution with the same rate parameter \\(\\lambda\\), then the likelihood function is the product of their individual probabilities:\n\\[\n\\mathcal{L}(\\lambda; Y_1, \\dots, Y_n) = \\prod_{i=1}^n \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\n\\[\n= e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}\n\\]\n\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef poisson_loglikelihood(lam, Y):\n \n    Y = np.array(Y)\n    \n    if lam &lt;= 0:\n        return -np.inf  # log-likelihood undefined for non-positive lambda\n\n    loglik = np.sum(-lam + Y * np.log(lam) - gammaln(Y + 1))\n    return loglik\n\n\nY = blueprinty['patents'].values \n\nlambda_vals = np.linspace(0.1, 10, 200)\n\nloglik_vals = [poisson_loglikelihood(lam, Y) for lam in lambda_vals]\n\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, loglik_vals, label='Log-Likelihood')\nplt.xlabel('Lambda (λ)')\nplt.ylabel('Log-Likelihood')\nplt.title('Poisson Log-Likelihood as a Function of λ')\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nlambda_mle = Y.mean()\nprint(\"MLE of lambda (λ̂):\", lambda_mle)\n\nMLE of lambda (λ̂): 3.6846666666666668\n\n\n\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\n\ndef neg_poisson_loglikelihood(lam):\n    if lam &lt;= 0:\n        return np.inf  \n    loglik = np.sum(-lam + Y * np.log(lam) - gammaln(Y + 1))\n    return -loglik  \ninitial_lambda = np.array([1.0])\n\nresult = minimize(neg_poisson_loglikelihood, initial_lambda, bounds=[(1e-6, None)])\n\nlambda_mle = result.x[0]\n\nprint(\"MLE of lambda (λ̂) from optimization:\", lambda_mle)\n\nMLE of lambda (λ̂) from optimization: 3.684666485763343\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    eta = X @ beta\n    lam = np.exp(eta)\n    loglik = np.sum(-lam + Y * eta - gammaln(Y + 1))\n    return -loglik\n\n\nimport numpy as np\nimport pandas as pd\n\n# Standardize age and create age_squared\nblueprinty['age'] = (blueprinty['age'] - blueprinty['age'].mean()) / blueprinty['age'].std()\nblueprinty['age_squared'] = blueprinty['age'] ** 2\n\n# One-hot encode region (excluding one as reference group)\nX_region = pd.get_dummies(blueprinty['region'], drop_first=True)\n\nX = pd.concat([\n    pd.Series(1, index=blueprinty.index, name='intercept'),\n    blueprinty[['age', 'age_squared']],\n    X_region,\n    blueprinty['iscustomer']\n], axis=1).astype(float)\n\ncolumn_names = X.columns.tolist()\nX = X.values\n\nY = blueprinty['patents'].values.astype(float)\n\nfrom scipy.optimize import minimize\n\ninitial_beta = np.zeros(X.shape[1])\n\nresult = minimize(\n    poisson_regression_loglikelihood,\n    initial_beta,\n    args=(Y, X),\n    method='BFGS'\n)\n\nbeta_mle = result.x\nhessian_inv = result.hess_inv  # inverse of Hessian (variance-covariance matrix)\n\nse_beta = np.sqrt(np.diag(hessian_inv))\n\nresults_df = pd.DataFrame({\n    'Coefficient': beta_mle,\n    'Std. Error': se_beta\n}, index=column_names)\n\nprint(results_df)\n\n             Coefficient  Std. Error\nintercept       1.344676    0.039609\nage            -0.057723    0.014982\nage_squared    -0.155814    0.013984\nNortheast       0.029170    0.045168\nNorthwest      -0.017575    0.054580\nSouth           0.056561    0.053275\nSouthwest       0.050576    0.048119\niscustomer      0.207591    0.031159\n\n\n\nimport statsmodels.api as sm\n\nmodel = sm.GLM(Y, X, family=sm.families.Poisson())\nresults = model.fit()\nprint(results.summary())\n\nglm_coef = results.params\nglm_se = results.bse\n\ncomparison_df = pd.DataFrame({\n    'Custom Coef': beta_mle,\n    'GLM Coef': glm_coef,\n    'Custom SE': se_beta,\n    'GLM SE': glm_se\n}, index=column_names)\n\nprint(comparison_df)\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        22:55:45   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.3447      0.038     35.059      0.000       1.270       1.420\nx1            -0.0577      0.015     -3.843      0.000      -0.087      -0.028\nx2            -0.1558      0.014    -11.513      0.000      -0.182      -0.129\nx3             0.0292      0.044      0.669      0.504      -0.056       0.115\nx4            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx5             0.0566      0.053      1.074      0.283      -0.047       0.160\nx6             0.0506      0.047      1.072      0.284      -0.042       0.143\nx7             0.2076      0.031      6.719      0.000       0.147       0.268\n==============================================================================\n             Custom Coef  GLM Coef  Custom SE    GLM SE\nintercept       1.344676  1.344676   0.039609  0.038355\nage            -0.057723 -0.057723   0.014982  0.015020\nage_squared    -0.155814 -0.155814   0.013984  0.013533\nNortheast       0.029170  0.029170   0.045168  0.043625\nNorthwest      -0.017575 -0.017575   0.054580  0.053781\nSouth           0.056561  0.056561   0.053275  0.052662\nSouthwest       0.050576  0.050576   0.048119  0.047198\niscustomer      0.207591  0.207591   0.031159  0.030895"
  },
  {
    "objectID": "blog/project4/hw2_questions.html#blueprinty-case-study",
    "href": "blog/project4/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd \n\nblueprinty = pd.read_csv('blueprinty.csv')\nblueprinty.head()\n\npatents_num = blueprinty.groupby('iscustomer')['patents'].mean()\npatents_num\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.histplot(data=blueprinty, x='patents', hue='iscustomer', multiple='stack', bins=20)\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.xlabel('Number of Patents')\nplt.ylabel('Count')\nplt.show()\n\n\n\n\n\n\n\n\n\nThe histogram shows that non-customers consistently outnumber customers across patent counts, with most entities, regardless of customer status, tend to hold 3–4 patents.\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nregion_counts = blueprinty.groupby(['iscustomer', 'region']).size().unstack()\n#print(region_counts)\n\nregion_counts.T.plot(kind='bar', stacked=True)\nplt.title('Customer Status by Region')\nplt.xlabel('Region')\nplt.ylabel('Count')\nplt.legend(title='Customer Status')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe chart shows that the Northeast has the highest overall customer count and a relatively balanced customer-to-non-customer ratio, while all other regions are dominated by non-customers.\n\n\nimport matplotlib.pyplot as plt\n\nblueprinty.boxplot(column='age', by='iscustomer')\nplt.title('Age Distribution by Customer Status')\nplt.suptitle('')\nplt.xlabel('Customer Status')\nplt.ylabel('Age')\nplt.show()\n\n\n\n\n\n\n\n\n\nThe age distribution for customers and non-customers is similar, with both groups centered around the mid-to-late 20s, though customers show slightly higher age variability and a marginally higher median\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nFor a random variable \\(Y \\sim \\text{Poisson}(\\lambda)\\), we consider the probability mass function (PMF):\n\\[\nf(Y \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^Y}{Y!}\n\\]\nIf we observe independent data points \\(Y_1, Y_2, \\dots, Y_n\\) from a Poisson distribution with the same rate parameter \\(\\lambda\\), then the likelihood function is the product of their individual probabilities:\n\\[\n\\mathcal{L}(\\lambda; Y_1, \\dots, Y_n) = \\prod_{i=1}^n \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\n\\[\n= e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n Y_i} \\prod_{i=1}^n \\frac{1}{Y_i!}\n\\]\n\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef poisson_loglikelihood(lam, Y):\n \n    Y = np.array(Y)\n    \n    if lam &lt;= 0:\n        return -np.inf  # log-likelihood undefined for non-positive lambda\n\n    loglik = np.sum(-lam + Y * np.log(lam) - gammaln(Y + 1))\n    return loglik\n\n\nY = blueprinty['patents'].values \n\nlambda_vals = np.linspace(0.1, 10, 200)\n\nloglik_vals = [poisson_loglikelihood(lam, Y) for lam in lambda_vals]\n\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, loglik_vals, label='Log-Likelihood')\nplt.xlabel('Lambda (λ)')\nplt.ylabel('Log-Likelihood')\nplt.title('Poisson Log-Likelihood as a Function of λ')\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nlambda_mle = Y.mean()\nprint(\"MLE of lambda (λ̂):\", lambda_mle)\n\nMLE of lambda (λ̂): 3.6846666666666668\n\n\n\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\n\ndef neg_poisson_loglikelihood(lam):\n    if lam &lt;= 0:\n        return np.inf  \n    loglik = np.sum(-lam + Y * np.log(lam) - gammaln(Y + 1))\n    return -loglik  \ninitial_lambda = np.array([1.0])\n\nresult = minimize(neg_poisson_loglikelihood, initial_lambda, bounds=[(1e-6, None)])\n\nlambda_mle = result.x[0]\n\nprint(\"MLE of lambda (λ̂) from optimization:\", lambda_mle)\n\nMLE of lambda (λ̂) from optimization: 3.684666485763343\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    eta = X @ beta\n    lam = np.exp(eta)\n    loglik = np.sum(-lam + Y * eta - gammaln(Y + 1))\n    return -loglik\n\n\nimport numpy as np\nimport pandas as pd\n\n# Standardize age and create age_squared\nblueprinty['age'] = (blueprinty['age'] - blueprinty['age'].mean()) / blueprinty['age'].std()\nblueprinty['age_squared'] = blueprinty['age'] ** 2\n\n# One-hot encode region (excluding one as reference group)\nX_region = pd.get_dummies(blueprinty['region'], drop_first=True)\n\nX = pd.concat([\n    pd.Series(1, index=blueprinty.index, name='intercept'),\n    blueprinty[['age', 'age_squared']],\n    X_region,\n    blueprinty['iscustomer']\n], axis=1).astype(float)\n\ncolumn_names = X.columns.tolist()\nX = X.values\n\nY = blueprinty['patents'].values.astype(float)\n\nfrom scipy.optimize import minimize\n\ninitial_beta = np.zeros(X.shape[1])\n\nresult = minimize(\n    poisson_regression_loglikelihood,\n    initial_beta,\n    args=(Y, X),\n    method='BFGS'\n)\n\nbeta_mle = result.x\nhessian_inv = result.hess_inv  # inverse of Hessian (variance-covariance matrix)\n\nse_beta = np.sqrt(np.diag(hessian_inv))\n\nresults_df = pd.DataFrame({\n    'Coefficient': beta_mle,\n    'Std. Error': se_beta\n}, index=column_names)\n\nprint(results_df)\n\n             Coefficient  Std. Error\nintercept       1.344676    0.039609\nage            -0.057723    0.014982\nage_squared    -0.155814    0.013984\nNortheast       0.029170    0.045168\nNorthwest      -0.017575    0.054580\nSouth           0.056561    0.053275\nSouthwest       0.050576    0.048119\niscustomer      0.207591    0.031159\n\n\n\nimport statsmodels.api as sm\n\nmodel = sm.GLM(Y, X, family=sm.families.Poisson())\nresults = model.fit()\nprint(results.summary())\n\nglm_coef = results.params\nglm_se = results.bse\n\ncomparison_df = pd.DataFrame({\n    'Custom Coef': beta_mle,\n    'GLM Coef': glm_coef,\n    'Custom SE': se_beta,\n    'GLM SE': glm_se\n}, index=column_names)\n\nprint(comparison_df)\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        22:55:45   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.3447      0.038     35.059      0.000       1.270       1.420\nx1            -0.0577      0.015     -3.843      0.000      -0.087      -0.028\nx2            -0.1558      0.014    -11.513      0.000      -0.182      -0.129\nx3             0.0292      0.044      0.669      0.504      -0.056       0.115\nx4            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx5             0.0566      0.053      1.074      0.283      -0.047       0.160\nx6             0.0506      0.047      1.072      0.284      -0.042       0.143\nx7             0.2076      0.031      6.719      0.000       0.147       0.268\n==============================================================================\n             Custom Coef  GLM Coef  Custom SE    GLM SE\nintercept       1.344676  1.344676   0.039609  0.038355\nage            -0.057723 -0.057723   0.014982  0.015020\nage_squared    -0.155814 -0.155814   0.013984  0.013533\nNortheast       0.029170  0.029170   0.045168  0.043625\nNorthwest      -0.017575 -0.017575   0.054580  0.053781\nSouth           0.056561  0.056561   0.053275  0.052662\nSouthwest       0.050576  0.050576   0.048119  0.047198\niscustomer      0.207591  0.207591   0.031159  0.030895"
  },
  {
    "objectID": "blog/project4/hw2_questions.html#results",
    "href": "blog/project4/hw2_questions.html#results",
    "title": "Poisson Regression Examples",
    "section": "Results",
    "text": "Results\nThe Poisson regression model indicates that age has a significant negative effect on patent counts, with each standard deviation increase in age associated with a 5.6% decrease in expected patents. The negative and significant age-squared term suggests a concave relationship, indicating that patent activity peaks and then declines with age. Customers are estimated to file 23% more patents than non-customers, a statistically significant difference. Regional differences are small and not statistically significant, suggesting that location has little effect on patent counts after accounting for other variables.\n\nX_0 = X.copy()\nX_1 = X.copy()\n\n# Assume 'iscustomer' is the **last column** in X\nX_0[:, -1] = 0  \nX_1[:, -1] = 1  \n\neta_0 = X_0 @ beta_mle\neta_1 = X_1 @ beta_mle\n\ny_pred_0 = np.exp(eta_0)  \ny_pred_1 = np.exp(eta_1)  \n\npatent_diff = y_pred_1 - y_pred_0\naverage_diff = np.mean(patent_diff)\nprint(\"Average increase in predicted patents due to Blueprinty's software:\", average_diff)\n\nAverage increase in predicted patents due to Blueprinty's software: 0.7927681250583442\n\n\nBased on the Poisson regression model, Blueprinty’s software is associated with an average increase of approximately 0.79 patents per firm. This estimate represents the expected difference in patent output if every firm were a customer versus if none were, holding age and region constant. The result suggests that Blueprinty’s software has a positive and meaningful effect on patent generation, supporting its potential value as an innovation-enhancing tool."
  },
  {
    "objectID": "blog/project4/hw2_questions.html#airbnb-case-study",
    "href": "blog/project4/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(\"airbnb.csv\")  \nprint(df.columns)\n\ndf.columns = df.columns.str.strip()\n\nrelevant_cols = [\n    'room_type', 'bathrooms', 'bedrooms', 'price', 'number_of_reviews',\n    'review_scores_cleanliness', 'review_scores_location', 'review_scores_value',\n    'instant_bookable'\n]\n\ndf_clean = df[relevant_cols].copy()\n\ndf_clean = df_clean.dropna()\n\ndf_clean['price'] = df_clean['price'].replace('[\\$,]', '', regex=True).astype(float)\n\n# Convert instant_bookable to binary\ndf_clean['instant_bookable'] = df_clean['instant_bookable'].map({'t': 1, 'f': 0})\n\ndf_clean = pd.get_dummies(df_clean, columns=['room_type'], drop_first=True)\n\n# Define y and X\ny = df_clean['number_of_reviews'].astype(float)\nX = df_clean.drop(columns=['number_of_reviews'])\n\n# Add intercept and ensure numeric types\nX = sm.add_constant(X).astype(float)\n\n# Fit Poisson model\npoisson_model = sm.GLM(y, X, family=sm.families.Poisson()).fit()\n\n# Display results\nprint(poisson_model.summary())\n\nIndex(['Unnamed: 0', 'id', 'days', 'last_scraped', 'host_since', 'room_type',\n       'bathrooms', 'bedrooms', 'price', 'number_of_reviews',\n       'review_scores_cleanliness', 'review_scores_location',\n       'review_scores_value', 'instant_bookable'],\n      dtype='object')\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                30160\nModel:                            GLM   Df Residuals:                    30150\nModel Family:                 Poisson   Df Model:                            9\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -5.2900e+05\nDate:                Wed, 07 May 2025   Deviance:                   9.3653e+05\nTime:                        22:55:45   Pearson chi2:                 1.41e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):             0.5649\nCovariance Type:            nonrobust                                         \n=============================================================================================\n                                coef    std err          z      P&gt;|z|      [0.025      0.975]\n---------------------------------------------------------------------------------------------\nconst                         3.5725      0.016    223.215      0.000       3.541       3.604\nbathrooms                    -0.1240      0.004    -33.091      0.000      -0.131      -0.117\nbedrooms                      0.0749      0.002     37.698      0.000       0.071       0.079\nprice                     -1.435e-05    8.3e-06     -1.729      0.084   -3.06e-05    1.92e-06\nreview_scores_cleanliness     0.1132      0.001     75.820      0.000       0.110       0.116\nreview_scores_location       -0.0768      0.002    -47.796      0.000      -0.080      -0.074\nreview_scores_value          -0.0915      0.002    -50.902      0.000      -0.095      -0.088\ninstant_bookable              0.3344      0.003    115.748      0.000       0.329       0.340\nroom_type_Private room       -0.0145      0.003     -5.310      0.000      -0.020      -0.009\nroom_type_Shared room        -0.2519      0.009    -29.229      0.000      -0.269      -0.235\n=============================================================================================\n\n\nThe model shows that listings with more bedrooms receive more reviews, while those with more bathrooms receive fewer. Specifically, each extra bedroom is linked to about an 7% increase in reviews, while each extra bathroom is linked to about a 12% decrease. Cleanliness ratings have a strong positive effect: higher cleanliness scores lead to significantly more reviews. In contrast, higher location and value scores are linked to fewer reviews. Listings with instant booking enabled get about 33% more reviews, suggesting guests prefer the convenience. Compared to entire homes, shared rooms get about 25% fewer reviews, while private rooms get slightly fewer reviews. These results show that cleanliness, convenience, and room type are key drivers of variation in review counts across listings."
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data\n\n\n\nI analyzed the data"
  },
  {
    "objectID": "blog/project1/index.html#section-1-data",
    "href": "blog/project1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/project1/index.html#section-2-analysis",
    "href": "blog/project1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jaqueline Vallejo Hinojosa",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "blog/project3/hw1_questions.html",
    "href": "blog/project3/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn their study, Karlan and List (2007) conducted a large-scale natural field experiment to investigate the role of price in charitable giving. The experiment involved more than 50,000 prior donors to a U.S.-based nonprofit organization. Individuals were randomly assigned to receive one of several types of fundraising letters: a control letter with no matching offer or a treatment letter offering matching grants at varying ratios—1:1, 2:1, or 3:1. Additionally, the researchers introduced random variation in the maximum match amount ($25,000, $50,000, $100,000, or unstated) and in the suggested donation amount (equal to, or 1.25 or 1.5 times the donor’s previous contribution).\nThe primary objective was to assess whether and to what extent price manipulation—via matching grants—affects donation behavior. The findings indicate that the mere announcement of a matching grant significantly increased both the likelihood of donation (by 22 percent) and the revenue per solicitation (by 19 percent). However, increasing the generosity of the match beyond a 1:1 ratio (i.e., to 2:1 or 3:1) yielded no additional gains in donation rates or amounts, challenging the prevailing assumption in fundraising practice that larger match ratios are more effective.\nFurthermore, the study revealed substantial heterogeneity in treatment effects across political contexts. The matching grant was significantly more effective in conservative-leaning (“red”) states than in liberal-leaning (“blue”) states, underscoring the importance of local sociopolitical context in moderating the effectiveness of economic incentives.\nThis experiment provides robust empirical evidence for the behavioral underpinnings of charitable giving and offers important insights for both economic theory and the practical design of fundraising campaigns.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project3/hw1_questions.html#introduction",
    "href": "blog/project3/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn their study, Karlan and List (2007) conducted a large-scale natural field experiment to investigate the role of price in charitable giving. The experiment involved more than 50,000 prior donors to a U.S.-based nonprofit organization. Individuals were randomly assigned to receive one of several types of fundraising letters: a control letter with no matching offer or a treatment letter offering matching grants at varying ratios—1:1, 2:1, or 3:1. Additionally, the researchers introduced random variation in the maximum match amount ($25,000, $50,000, $100,000, or unstated) and in the suggested donation amount (equal to, or 1.25 or 1.5 times the donor’s previous contribution).\nThe primary objective was to assess whether and to what extent price manipulation—via matching grants—affects donation behavior. The findings indicate that the mere announcement of a matching grant significantly increased both the likelihood of donation (by 22 percent) and the revenue per solicitation (by 19 percent). However, increasing the generosity of the match beyond a 1:1 ratio (i.e., to 2:1 or 3:1) yielded no additional gains in donation rates or amounts, challenging the prevailing assumption in fundraising practice that larger match ratios are more effective.\nFurthermore, the study revealed substantial heterogeneity in treatment effects across political contexts. The matching grant was significantly more effective in conservative-leaning (“red”) states than in liberal-leaning (“blue”) states, underscoring the importance of local sociopolitical context in moderating the effectiveness of economic incentives.\nThis experiment provides robust empirical evidence for the behavioral underpinnings of charitable giving and offers important insights for both economic theory and the practical design of fundraising campaigns.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project3/hw1_questions.html#data",
    "href": "blog/project3/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nimport pandas as pd\n\nkarlan_list_2007 = pd.read_stata('karlan_list_2007.dta')\nkarlan_list_2007.head() # shows the first 5 rows of the data\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\nDescription\nThe dataset consists of 50,083 observations and 51 variables, capturing a wide range of information related to donation behavior, treatment effects, demographics, and geographic/political context. Key variables include treatment and control group indicators, donation amounts, and various “ask” strategies, along with demographic attributes like gender, education, and income. It also includes regional data such as state-level responses and political leanings.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nfrom scipy import stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# T-test: months since last donation (mrm2)\ntreat_group = karlan_list_2007[karlan_list_2007['treatment'] == 1]['mrm2']\ncontrol_group = karlan_list_2007[karlan_list_2007['control'] == 1]['mrm2']\nt_stat, p_val = stats.ttest_ind(treat_group, control_group, nan_policy='omit')\nprint(\"T-test results:\", t_stat, p_val)\n\n# Regression: mrm2 ~ treatment\nmodel = smf.ols('mrm2 ~ treatment', data=karlan_list_2007).fit()\nprint(model.summary())\n\nT-test results: 0.1194921058159193 0.9048859731777738\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Wed, 07 May 2025   Prob (F-statistic):              0.905\nTime:                        22:55:40   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nVariable tested: mrm2 (months since last donation)\nBased on the T-test, the difference in means between treatment and control is very small and statistically insignificant at the 95% confidence level. A p-value of 0.905 is far above the 0.05 threshold, suggesting no meaningful difference in mrm2 between groups.\nIn the linear regression, the coefficient is nearly 0 and has a p-value of 0.905 which confirms the t-test. Hence, both tests indicate no statistically significant difference between the treatment and control groups in months since last donation. This supports the validity of the randomization: the groups appear well-balanced on this baseline covariate.\n\nfrom scipy import stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# T-test: number of prior donations (freq)\ntreat_group = karlan_list_2007[karlan_list_2007['treatment'] == 1]['freq']\ncontrol_group = karlan_list_2007[karlan_list_2007['control'] == 1]['freq']\nt_stat, p_val = stats.ttest_ind(treat_group, control_group, nan_policy='omit')\nprint(\"T-test results:\", t_stat, p_val)\n\n# Regression: freq ~ treatment\nmodel = smf.ols('freq ~ treatment', data=karlan_list_2007).fit()\nprint(model.summary())\n\nT-test results: -0.11089297035979982 0.9117016644344591\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   freq   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01230\nDate:                Wed, 07 May 2025   Prob (F-statistic):              0.912\nTime:                        22:55:40   Log-Likelihood:            -1.9292e+05\nNo. Observations:               50083   AIC:                         3.858e+05\nDf Residuals:                   50081   BIC:                         3.859e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      8.0473      0.088     91.231      0.000       7.874       8.220\ntreatment     -0.0120      0.108     -0.111      0.912      -0.224       0.200\n==============================================================================\nOmnibus:                    49107.114   Durbin-Watson:                   2.016\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          3644795.393\nSkew:                           4.707   Prob(JB):                         0.00\nKurtosis:                      43.718   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nVariable tested: freq (number of prior donations)\nBased on the T-test, the difference in means between treatment and control is statistically insignificant. The p-value of 0.912 is far above the 0.05 threshold, suggesting no meaningful pre-treatment difference.\nAgain, the results from the linear regression perfectly match the t-test. The coefficient is very close to zero, and the p-value confirms no significant difference in donation frequency between the groups. These results indicate that freq is well-balanced between the treatment and control groups prior to the intervention. This supports the idea that any differences in outcomes after the intervention are not due to pre-existing group differences in donation behavior.\nTable 1 in research papers shows baseline comparisons like the ones above. Its purpose is to demonstrate that the treatment and control groups were similar on observable characteristics before the intervention, which boosts the credibility of the study’s causal claims. If there’s no big difference in key variables before treatment, we can more confidently attribute post-treatment differences to the treatment itself"
  },
  {
    "objectID": "blog/project3/hw1_questions.html#experimental-results",
    "href": "blog/project3/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\ngrouped = karlan_list_2007.groupby('treatment')['gave'].mean()\ngrouped.plot(kind='bar')\nplt.ylabel('Proportion Donated')\nplt.xlabel('Groups')\nplt.xticks([0, 1], ['Control', 'Treatment'], rotation=0)\nplt.title('Donation Rate by Group')\nplt.show()\n\n\n\n\n\n\n\n\n\n# T-test\ngave_treat = karlan_list_2007[karlan_list_2007['treatment'] == 1]['gave']\ngave_control = karlan_list_2007[karlan_list_2007['control'] == 1]['gave']\nt_stat, p_val = stats.ttest_ind(gave_treat, gave_control, nan_policy='omit')\nprint(\"T-test on donation:\", t_stat, p_val)\n\nT-test on donation: 3.101361000543946 0.0019274025949016988\n\n\nt-statistic = 3.10: The difference in donation rates between the treatment and control groups is about 3 standard errors away from 0.\np-value = 0.0019: This difference is statistically significant at the %1 level meaning that it’s strong evidence that the treatment affected donation behavior. Hence, people in the treatment group were significantly more likely to donate than those in the control group.\n\n# Regression\nmodel = smf.ols('gave ~ treatment', data=karlan_list_2007).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 07 May 2025   Prob (F-statistic):            0.00193\nTime:                        22:55:40   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nIntercept (0.0179): The baseline donation rate in the control group is 1.79%\nTreatment coefficient (0.0042): Being assigned to the treatment group increases the probability of donating by 0.42 percentage points.Thus, on average, people in the treatment group donated at a rate that was 0.42 percentage points higher than the control group.\np = 0.002 for treatment: This increase is statistically significant hence we’re confident is not just due to random chance.\n\nprobit_model = smf.probit('gave ~ treatment', data=karlan_list_2007).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 07 May 2025   Pseudo R-squ.:               0.0009783\nTime:                        22:55:41   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nAssignment to the treatment group increases the latent propensity to donate (the z-score of the probability) by 0.087, which is statistically significant at the 1% level.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nfrom scipy import stats\n\n# Filter dataset for only treatment group observations\ntreatments = karlan_list_2007[karlan_list_2007['treatment'] == 1]\n\n# Groups by match ratio\ngave_1to1 = treatments[treatments['ratio'] == 1]['gave']\ngave_2to1 = treatments[treatments['ratio'] == 2]['gave']\ngave_3to1 = treatments[treatments['ratio'] == 3]['gave']\n\n# T-test: 2:1 vs 1:1\nt1, p1 = stats.ttest_ind(gave_2to1, gave_1to1, nan_policy='omit')\nprint(\"2:1 vs 1:1 --&gt; t =\", t1, \", p =\", p1)\n\n# T-test: 3:1 vs 1:1\nt2, p2 = stats.ttest_ind(gave_3to1, gave_1to1, nan_policy='omit')\nprint(\"3:1 vs 1:1 --&gt; t =\", t2, \", p =\", p2)\n\n# T-test: 3:1 vs 2:1\nt3, p3 = stats.ttest_ind(gave_3to1, gave_2to1, nan_policy='omit')\nprint(\"3:1 vs 2:1 --&gt; t =\", t3, \", p =\", p3)\n\n2:1 vs 1:1 --&gt; t = 0.96504713432247 , p = 0.33453168549723933\n3:1 vs 1:1 --&gt; t = 1.0150255853798622 , p = 0.3101046637086672\n3:1 vs 2:1 --&gt; t = 0.05011583793874515 , p = 0.9600305283739325\n\n\nGiven that the p-values are greater than 0.05, there is no statistically significant difference in donation rates between match ratios. This supports the authors’ comment that larger match ratios do not lead to additional increases in giving.\n\n# Creates ratio1 variable\nkarlan_list_2007['ratio1'] = (karlan_list_2007['ratio'] == 1).astype(int)\n\n# Regression on match ratios\nmodel = smf.ols('gave ~ ratio1 + ratio2 + ratio3', data=karlan_list_2007).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Wed, 07 May 2025   Prob (F-statistic):             0.0118\nTime:                        22:55:41   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nCompared to the baseline group (control group), 2:1 and 3:1 match offers significantly increase the probability of donating, by about half a percentage point. However, there is no meaningful difference between 2:1 and 3:1, and 1:1 is not significantly different from the control.\n\n# Only treatment group, since ratios apply there\ntreatments = karlan_list_2007[karlan_list_2007['treatment'] == 1]\n\n# Calculate response rates from data\nrate_1to1 = treatments[treatments['ratio'] == 1]['gave'].mean()\nrate_2to1 = treatments[treatments['ratio'] == 2]['gave'].mean()\nrate_3to1 = treatments[treatments['ratio'] == 3]['gave'].mean()\n\n# Differences\ndiff_2_vs_1 = rate_2to1 - rate_1to1\ndiff_3_vs_2 = rate_3to1 - rate_2to1\n\nprint(\"2:1 vs 1:1 (data difference):\", diff_2_vs_1)\nprint(\"3:1 vs 2:1 (data difference):\", diff_3_vs_2)\n\n# From regression coefficients\ndiff_coef_2_vs_1 = 0.0048 - 0.0029\ndiff_coef_3_vs_2 = 0.0049 - 0.0048\n\nprint(\"2:1 vs 1:1 (coefficient difference):\", diff_coef_2_vs_1)\nprint(\"3:1 vs 2:1 (coefficient difference):\", diff_coef_3_vs_2)\n\n2:1 vs 1:1 (data difference): 0.0018842510217149944\n3:1 vs 2:1 (data difference): 0.00010002398025293902\n2:1 vs 1:1 (coefficient difference): 0.0018999999999999998\n3:1 vs 2:1 (coefficient difference): 0.00010000000000000026\n\n\nBased on the differences, offering a matched donation increases the likelihood that people will give, but increasing the match ratio beyond 1:1 has limited additional effect. The difference between 1:1 and 2:1 matches shows a small improvement in donation rates, but going from 2:1 to 3:1 does not lead to further gains. This suggests that while the presence of a match is important, making the match more generous doesn’t necessarily make it more effective.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Everyone\nmodel = smf.ols('amount ~ treatment', data=karlan_list_2007).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 07 May 2025   Prob (F-statistic):             0.0628\nTime:                        22:55:41   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThis regression analyzes the effect of treatment assignment on the average donation amount, including both donors and non-donors. The estimated coefficient for the treatment group is positive ($0.15), indicating a modest increase in average contributions; however, the effect is not statistically significant at conventional levels (p = 0.063). These results suggest limited evidence that the treatment influences donation amounts in the full sample. Given the large proportion of zero donations, the average amount is likely driven by non-donors, underscoring the importance of analyzing conditional effects among donors separately\n\n# Only those who donated\ndonors = karlan_list_2007[karlan_list_2007['gave'] == 1]\nmodel_donors = smf.ols('amount ~ treatment', data=donors).fit()\nprint(model_donors.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 07 May 2025   Prob (F-statistic):              0.561\nTime:                        22:55:41   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nAmong those who donated, the treatment had no significant effect on how much they gave. However, because the analysis conditions on a post-treatment outcome, the estimated effect is not causally valid as it introduces bias.\n\n# Plot histograms\nfig, axs = plt.subplots(1, 2, figsize=(12, 5))\nfor i, group in enumerate(['control', 'treatment']):\n    data = donors[donors[group] == 1]['amount']\n    axs[i].hist(data, bins=30, edgecolor='black')\n    mean_val = data.mean()\n    axs[i].axvline(mean_val, color='red', linestyle='dashed',linewidth=2,label=f'Mean: ${mean_val:.2f}')\n    axs[i].set_title(f'{group.title()} Group')\n    axs[i].set_xlabel('Donation Amount')\n    axs[i].set_ylabel('Frequency')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe plots above display the distribution of donation amounts for both the control and treatment groups. The red dashed line in each plot indicates the sample mean within that group."
  },
  {
    "objectID": "blog/project3/hw1_questions.html#simulation-experiment",
    "href": "blog/project3/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\n\ncontrol_draws = np.random.binomial(1, 0.018, 100000)\ntreatment_draws = np.random.binomial(1, 0.022, 100000)\ndiffs = treatment_draws - control_draws\ncumulative_avg = np.cumsum(diffs) / np.arange(1, len(diffs)+1)\n\nplt.plot(cumulative_avg)\nplt.axhline(0.004, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title('Cumulative Average of Differences')\nplt.xlabel('Simulation Number')\nplt.ylabel('Cumulative Avg Difference')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nBased on the plot, we can observe that the cumulative average of the simulated differences gradually stabilizes and converges toward the true difference in means (0.004), represented by the red dashed line. The average begins to smooth out closely around the true value as the number of simulations increases, clearly demonstrating the Law of Large Number.\n\n\nCentral Limit Theorem\n\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axs = plt.subplots(2, 2, figsize=(12, 10))\nfor i, n in enumerate(sample_sizes):\n    avg_diffs = []\n    for _ in range(1000):\n        control = np.random.binomial(1, 0.018, n)\n        treatment = np.random.binomial(1, 0.022, n)\n        avg_diffs.append(np.mean(treatment) - np.mean(control))\n    \n    ax = axs[i//2][i%2]\n    ax.hist(avg_diffs, bins=30, edgecolor='black')\n    ax.axvline(np.mean(avg_diffs), color='red', linestyle='--')\n    ax.set_title(f'Sample Size: {n}')\n    ax.set_xlabel('Difference in Means')\n    ax.set_ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIn the plots with smaller sample sizes (50, 200), zero tends to lie near the center of the distribution because the sampling variability is high and the true difference is small. As the sample size increases (500, 100), the distribution becomes narrower around the true mean difference (which is slightly above zero), and zero shifts toward the tail of the distribution. This indicates that with larger samples, the observed difference becomes more statistically distinguishable from zero."
  },
  {
    "objectID": "blog/project2/index.html",
    "href": "blog/project2/index.html",
    "title": "This is Project 2",
    "section": "",
    "text": "I cleaned some data\n\n\n\nI analyzed the data"
  },
  {
    "objectID": "blog/project2/index.html#section-1-data",
    "href": "blog/project2/index.html#section-1-data",
    "title": "This is Project 2",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/project2/index.html#section-2-analysis",
    "href": "blog/project2/index.html#section-2-analysis",
    "title": "This is Project 2",
    "section": "",
    "text": "I analyzed the data"
  }
]