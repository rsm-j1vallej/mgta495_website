---
title: "A Replication of Karlan and List (2007)"
author: "Jaqueline Vallejo Hinojosa"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

In their study, Karlan and List (2007) conducted a large-scale natural field experiment to investigate the role of price in charitable giving. The experiment involved more than 50,000 prior donors to a U.S.-based nonprofit organization. Individuals were randomly assigned to receive one of several types of fundraising letters: a control letter with no matching offer or a treatment letter offering matching grants at varying ratios—1:1, 2:1, or 3:1. Additionally, the researchers introduced random variation in the maximum match amount ($25,000, $50,000, $100,000, or unstated) and in the suggested donation amount (equal to, or 1.25 or 1.5 times the donor’s previous contribution).

The primary objective was to assess whether and to what extent price manipulation—via matching grants—affects donation behavior. The findings indicate that the mere announcement of a matching grant significantly increased both the likelihood of donation (by 22 percent) and the revenue per solicitation (by 19 percent). However, increasing the generosity of the match beyond a 1:1 ratio (i.e., to 2:1 or 3:1) yielded no additional gains in donation rates or amounts, challenging the prevailing assumption in fundraising practice that larger match ratios are more effective.

Furthermore, the study revealed substantial heterogeneity in treatment effects across political contexts. The matching grant was significantly more effective in conservative-leaning ("red") states than in liberal-leaning ("blue") states, underscoring the importance of local sociopolitical context in moderating the effectiveness of economic incentives.

This experiment provides robust empirical evidence for the behavioral underpinnings of charitable giving and offers important insights for both economic theory and the practical design of fundraising campaigns.

This project seeks to replicate their results.

## Data
```{python}
import pandas as pd

karlan_list_2007 = pd.read_stata('karlan_list_2007.dta')
karlan_list_2007.head() # shows the first 5 rows of the data
```

### Description

The dataset consists of 50,083 observations and 51 variables, capturing a wide range of information related to donation behavior, treatment effects, demographics, and geographic/political context. Key variables include treatment and control group indicators, donation amounts, and various "ask" strategies, along with demographic attributes like gender, education, and income. It also includes regional data such as state-level responses and political leanings.

:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::


### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

```{python}
from scipy import stats
import statsmodels.api as sm
import statsmodels.formula.api as smf

# T-test: months since last donation (mrm2)
treat_group = karlan_list_2007[karlan_list_2007['treatment'] == 1]['mrm2']
control_group = karlan_list_2007[karlan_list_2007['control'] == 1]['mrm2']
t_stat, p_val = stats.ttest_ind(treat_group, control_group, nan_policy='omit')
print("T-test results:", t_stat, p_val)

# Regression: mrm2 ~ treatment
model = smf.ols('mrm2 ~ treatment', data=karlan_list_2007).fit()
print(model.summary())
```

**Variable tested:** mrm2 (months since last donation)

Based on the T-test, the difference in means between treatment and control is very small and statistically insignificant at the 95% confidence level. A p-value of 0.905 is far above the 0.05 threshold, suggesting no meaningful difference in mrm2 between groups. 

In the linear regression, the coefficient is nearly 0 and has a p-value of 0.905 which confirms the t-test. Hence, both tests indicate no statistically significant difference between the treatment and control groups in months since last donation. This supports the validity of the randomization: the groups appear well-balanced on this baseline covariate. 

```{python}
from scipy import stats
import statsmodels.api as sm
import statsmodels.formula.api as smf

# T-test: number of prior donations (freq)
treat_group = karlan_list_2007[karlan_list_2007['treatment'] == 1]['freq']
control_group = karlan_list_2007[karlan_list_2007['control'] == 1]['freq']
t_stat, p_val = stats.ttest_ind(treat_group, control_group, nan_policy='omit')
print("T-test results:", t_stat, p_val)

# Regression: freq ~ treatment
model = smf.ols('freq ~ treatment', data=karlan_list_2007).fit()
print(model.summary())
```

**Variable tested:** freq (number of prior donations)

Based on the T-test, the difference in means between treatment and control is statistically insignificant. The p-value of 0.912 is far above the 0.05 threshold, suggesting no meaningful pre-treatment difference. 

Again, the results from the linear regression perfectly match the t-test. The coefficient is very close to zero, and the p-value confirms no significant difference in donation frequency between the groups. These results indicate that freq is well-balanced between the treatment and control groups prior to the intervention. This supports the idea that any differences in outcomes after the intervention are not due to pre-existing group differences in donation behavior.

Table 1 in research papers shows baseline comparisons like the ones above. Its purpose is to demonstrate that the treatment and control groups were similar on observable characteristics before the intervention, which boosts the credibility of the study’s causal claims. If there's no big difference in key variables before treatment, we can more confidently attribute post-treatment differences to the treatment itself

## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

```{python}
import matplotlib.pyplot as plt

grouped = karlan_list_2007.groupby('treatment')['gave'].mean()
grouped.plot(kind='bar')
plt.ylabel('Proportion Donated')
plt.xlabel('Groups')
plt.xticks([0, 1], ['Control', 'Treatment'], rotation=0)
plt.title('Donation Rate by Group')
plt.show()
```

```{python}
# T-test
gave_treat = karlan_list_2007[karlan_list_2007['treatment'] == 1]['gave']
gave_control = karlan_list_2007[karlan_list_2007['control'] == 1]['gave']
t_stat, p_val = stats.ttest_ind(gave_treat, gave_control, nan_policy='omit')
print("T-test on donation:", t_stat, p_val)
``` 

**t-statistic = 3.10:** The difference in donation rates between the treatment and control groups is about 3 standard errors away from 0.

**p-value = 0.0019:** This difference is statistically significant at the %1 level meaning that it's strong evidence that the treatment affected donation behavior. Hence, people in the treatment group were significantly more likely to donate than those in the control group.

```{python}
# Regression
model = smf.ols('gave ~ treatment', data=karlan_list_2007).fit()
print(model.summary())
```

**Intercept (0.0179):** The baseline donation rate in the control group is 1.79%

**Treatment coefficient (0.0042):** Being assigned to the treatment group increases the probability of donating by 0.42 percentage points.Thus, on average, people in the treatment group donated at a rate that was 0.42 percentage points higher than the control group. 

**p = 0.002 for treatment:** This increase is statistically significant hence we're confident is not just due to random chance.

```{python}
probit_model = smf.probit('gave ~ treatment', data=karlan_list_2007).fit()
print(probit_model.summary())
```

Assignment to the treatment group increases the latent propensity to donate (the z-score of the probability) by 0.087, which is statistically significant at the 1% level.

### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

```{python}
from scipy import stats

# Filter dataset for only treatment group observations
treatments = karlan_list_2007[karlan_list_2007['treatment'] == 1]

# Groups by match ratio
gave_1to1 = treatments[treatments['ratio'] == 1]['gave']
gave_2to1 = treatments[treatments['ratio'] == 2]['gave']
gave_3to1 = treatments[treatments['ratio'] == 3]['gave']

# T-test: 2:1 vs 1:1
t1, p1 = stats.ttest_ind(gave_2to1, gave_1to1, nan_policy='omit')
print("2:1 vs 1:1 --> t =", t1, ", p =", p1)

# T-test: 3:1 vs 1:1
t2, p2 = stats.ttest_ind(gave_3to1, gave_1to1, nan_policy='omit')
print("3:1 vs 1:1 --> t =", t2, ", p =", p2)

# T-test: 3:1 vs 2:1
t3, p3 = stats.ttest_ind(gave_3to1, gave_2to1, nan_policy='omit')
print("3:1 vs 2:1 --> t =", t3, ", p =", p3)
```

Given that the p-values are greater than 0.05, there is no statistically significant difference in donation rates between match ratios. This supports the authors' comment that larger match ratios do not lead to additional increases in giving.

```{python}
# Creates ratio1 variable
karlan_list_2007['ratio1'] = (karlan_list_2007['ratio'] == 1).astype(int)

# Regression on match ratios
model = smf.ols('gave ~ ratio1 + ratio2 + ratio3', data=karlan_list_2007).fit()
print(model.summary())
```

Compared to the baseline group (control group), 2:1 and 3:1 match offers significantly increase the probability of donating, by about half a percentage point. However, there is no meaningful difference between 2:1 and 3:1, and 1:1 is not significantly different from the control.  

```{python}
# Only treatment group, since ratios apply there
treatments = karlan_list_2007[karlan_list_2007['treatment'] == 1]

# Calculate response rates from data
rate_1to1 = treatments[treatments['ratio'] == 1]['gave'].mean()
rate_2to1 = treatments[treatments['ratio'] == 2]['gave'].mean()
rate_3to1 = treatments[treatments['ratio'] == 3]['gave'].mean()

# Differences
diff_2_vs_1 = rate_2to1 - rate_1to1
diff_3_vs_2 = rate_3to1 - rate_2to1

print("2:1 vs 1:1 (data difference):", diff_2_vs_1)
print("3:1 vs 2:1 (data difference):", diff_3_vs_2)

# From regression coefficients
diff_coef_2_vs_1 = 0.0048 - 0.0029
diff_coef_3_vs_2 = 0.0049 - 0.0048

print("2:1 vs 1:1 (coefficient difference):", diff_coef_2_vs_1)
print("3:1 vs 2:1 (coefficient difference):", diff_coef_3_vs_2)
```

Based on the differences, offering a matched donation increases the likelihood that people will give, but increasing the match ratio beyond 1:1 has limited additional effect. The difference between 1:1 and 2:1 matches shows a small improvement in donation rates, but going from 2:1 to 3:1 does not lead to further gains. This suggests that while the presence of a match is important, making the match more generous doesn’t necessarily make it more effective.

### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

```{python}
# Everyone
model = smf.ols('amount ~ treatment', data=karlan_list_2007).fit()
print(model.summary())
```

This regression analyzes the effect of treatment assignment on the average donation amount, including both donors and non-donors. The estimated coefficient for the treatment group is positive ($0.15), indicating a modest increase in average contributions; however, the effect is not statistically significant at conventional levels (p = 0.063). These results suggest limited evidence that the treatment influences donation amounts in the full sample. Given the large proportion of zero donations, the average amount is likely driven by non-donors, underscoring the importance of analyzing conditional effects among donors separately

```{python}
# Only those who donated
donors = karlan_list_2007[karlan_list_2007['gave'] == 1]
model_donors = smf.ols('amount ~ treatment', data=donors).fit()
print(model_donors.summary())
```

Among those who donated, the treatment had no significant effect on how much they gave. However, because the analysis conditions on a post-treatment outcome, the estimated effect is not causally valid as it introduces bias.

```{python}
# Plot histograms
fig, axs = plt.subplots(1, 2, figsize=(12, 5))
for i, group in enumerate(['control', 'treatment']):
    data = donors[donors[group] == 1]['amount']
    axs[i].hist(data, bins=30, edgecolor='black')
    mean_val = data.mean()
    axs[i].axvline(mean_val, color='red', linestyle='dashed',linewidth=2,label=f'Mean: ${mean_val:.2f}')
    axs[i].set_title(f'{group.title()} Group')
    axs[i].set_xlabel('Donation Amount')
    axs[i].set_ylabel('Frequency')
plt.tight_layout()
plt.show()
```

The plots above display the distribution of donation amounts for both the control and treatment groups. The red dashed line in each plot indicates the sample mean within that group.

## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers

```{python}
import numpy as np

control_draws = np.random.binomial(1, 0.018, 100000)
treatment_draws = np.random.binomial(1, 0.022, 100000)
diffs = treatment_draws - control_draws
cumulative_avg = np.cumsum(diffs) / np.arange(1, len(diffs)+1)

plt.plot(cumulative_avg)
plt.axhline(0.004, color='red', linestyle='--', label='True Difference (0.004)')
plt.title('Cumulative Average of Differences')
plt.xlabel('Simulation Number')
plt.ylabel('Cumulative Avg Difference')
plt.legend()
plt.show()
```

Based on the plot, we can observe that the cumulative average of the simulated differences gradually stabilizes and converges toward the true difference in means (0.004), represented by the red dashed line. The average begins to smooth out closely around the true value as the number of simulations increases, clearly demonstrating the Law of Large Number.

### Central Limit Theorem

```{python}
sample_sizes = [50, 200, 500, 1000]

fig, axs = plt.subplots(2, 2, figsize=(12, 10))
for i, n in enumerate(sample_sizes):
    avg_diffs = []
    for _ in range(1000):
        control = np.random.binomial(1, 0.018, n)
        treatment = np.random.binomial(1, 0.022, n)
        avg_diffs.append(np.mean(treatment) - np.mean(control))
    
    ax = axs[i//2][i%2]
    ax.hist(avg_diffs, bins=30, edgecolor='black')
    ax.axvline(np.mean(avg_diffs), color='red', linestyle='--')
    ax.set_title(f'Sample Size: {n}')
    ax.set_xlabel('Difference in Means')
    ax.set_ylabel('Frequency')

plt.tight_layout()
plt.show()
```

In the plots with smaller sample sizes (50, 200), zero tends to lie near the center of the distribution because the sampling variability is high and the true difference is small. As the sample size increases (500, 100), the distribution becomes narrower around the true mean difference (which is slightly above zero), and zero shifts toward the tail of the distribution. This indicates that with larger samples, the observed difference becomes more statistically distinguishable from zero.